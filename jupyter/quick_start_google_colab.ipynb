{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quick_start_google_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph3bDypIEXdd"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaVmDt1TEXdh"
      },
      "source": [
        "# Spark NLP Quick Start\n",
        "### How to use Spark NLP pretrained pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkbpOBs6DasA"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/quick_start_google_colab.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtCa0sZ8EXdj"
      },
      "source": [
        "We will first set up the runtime environment and then load pretrained Entity Recognition model and Sentiment analysis model and give it a quick test. Feel free to test the models on your own sentences / datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyMMD_upEfIa",
        "outputId": "a0a82e0b-e4ad-47e6-abff-a4b93d35a776"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "!apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q \"https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\" > /dev/null\n",
        "!tar -xvf spark-3.1.1-bin-hadoop2.7.tgz > /dev/null\n",
        "!pip install -q findspark\n",
        "\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\"\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install spark-nlp and pyspark\n",
        "! pip install spark-nlp==3.0.0 pyspark==3.1.1\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_282\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_282-8u282-b08-0ubuntu1~18.04-b08)\n",
            "OpenJDK 64-Bit Server VM (build 25.282-b08, mixed mode)\n",
            "Requirement already satisfied: spark-nlp==3.0.0 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: pyspark==3.1.1 in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark==3.1.1) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "5in-TmzGEXdk",
        "outputId": "311b96c8-62e1-4cb3-dabd-2dde7d66df7f"
      },
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: {}\".format(sparknlp.version()))\n",
        "print(\"Apache Spark version: {}\".format(spark.version))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version\n",
            "Apache Spark version\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.1.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt1KiTMFEXdp"
      },
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtGm-OY4EXds"
      },
      "source": [
        "Let's use Spark NLP pre-trained pipeline for `named entity recognition`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNu3meQKEXdu",
        "outputId": "1361e928-b764-4385-dce1-a531a859785c"
      },
      "source": [
        "pipeline = PretrainedPipeline('recognize_entities_dl', 'en')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recognize_entities_dl download started this may take some time.\n",
            "Approx size to download 160.1 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMzyLyftEXdy"
      },
      "source": [
        "result = pipeline.annotate('Harry Potter is a great movie') "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ark1N0GEXd1",
        "outputId": "2b98929d-7212-45c6-f760-80f7f288e46a"
      },
      "source": [
        "print(result['ner'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['B-PER', 'I-PER', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EKcEN_oEXd9"
      },
      "source": [
        "Let's use Spark NLP pre-trained pipeline for `sentiment` analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4ZXQDnlEXd-",
        "outputId": "bbee27fd-7834-4c35-e21e-91357fd66722"
      },
      "source": [
        "pipeline = PretrainedPipeline('analyze_sentimentdl_glove_imdb', 'en')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "analyze_sentimentdl_glove_imdb download started this may take some time.\n",
            "Approx size to download 155.3 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73O-w8IYEXeC"
      },
      "source": [
        "result = pipeline.annotate(\"Harry Potter is a great movie.\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joIUX2P4EXeJ",
        "outputId": "c275c0bd-5ba9-4054-cb0e-c477fcf3ae24"
      },
      "source": [
        "print(result['sentiment'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['pos']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-qhkjkWVCTm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}