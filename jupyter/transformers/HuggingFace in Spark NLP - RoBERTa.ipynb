{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HuggingFace in Spark NLP - RoBERTa.ipynb","provenance":[{"file_id":"1C6-jMjzLBMs8WkLfeqHvv1Se9LNfqYZW","timestamp":1622475523612},{"file_id":"1wPsMf2tqrA0uR_qfBT4HY_CozriMZUBF","timestamp":1622473868648}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOxMgQPORlrTziNkN60Klb3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"35e5ee38bc1c437b8df70d2eae183389":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_788e3ef4ec61409caf40cc45e23f2f1f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a7b6bc5963af4756ad490e86305f5e24","IPY_MODEL_524d70accce44a1296b2bf8cd9044ebf"]}},"788e3ef4ec61409caf40cc45e23f2f1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a7b6bc5963af4756ad490e86305f5e24":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0ab09f97b5114624b03cda86be5814a8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_943998b3cb204d8489ae0c71081e0390"}},"524d70accce44a1296b2bf8cd9044ebf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e3866d1d10c74297abd8fe945bfa574e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:06&lt;00:00, 133kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0e1999f605a44ec089d3d27a5e6d1874"}},"0ab09f97b5114624b03cda86be5814a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"943998b3cb204d8489ae0c71081e0390":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e3866d1d10c74297abd8fe945bfa574e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0e1999f605a44ec089d3d27a5e6d1874":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"39c01f1f92ce4ecb89e7bafba714ecb3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_97e54be966dc4aeebadf2d77161296a8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5bdca68c26394bc8857c14ca792c8e7d","IPY_MODEL_be5a115938c04631a834020b4426fd11"]}},"97e54be966dc4aeebadf2d77161296a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5bdca68c26394bc8857c14ca792c8e7d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e81d493c5510490da6655865f859d82f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bba854c507044daf8136a9b3368317fa"}},"be5a115938c04631a834020b4426fd11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9240418ef66b42f4b0e4a4b78520bc9f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:04&lt;00:00, 95.9kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a646ecf1a46b4d92a03c417fa44bd517"}},"e81d493c5510490da6655865f859d82f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bba854c507044daf8136a9b3368317fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9240418ef66b42f4b0e4a4b78520bc9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a646ecf1a46b4d92a03c417fa44bd517":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a0b574ea85694a09a617848c2d98ed77":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_91dc248081da4e12babe1ac606cc80b1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cd4c3c270a0e42b4bae48a161099483d","IPY_MODEL_220c79e165df4ea59ae5c61abab6493b"]}},"91dc248081da4e12babe1ac606cc80b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cd4c3c270a0e42b4bae48a161099483d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dd386f5a79b848458aab9b34179e9351","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2c57da9a378042ebaa510f6d58eef27c"}},"220c79e165df4ea59ae5c61abab6493b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5ed79516254d41cf99ec61e552d52b36","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:00&lt;00:00, 1.75MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_44387ff2654445c1b304e9ad0ebdda2b"}},"dd386f5a79b848458aab9b34179e9351":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2c57da9a378042ebaa510f6d58eef27c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ed79516254d41cf99ec61e552d52b36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"44387ff2654445c1b304e9ad0ebdda2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"af56cc3ec8044118904cd7e5043e246d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_73a77396295d481584ba3ff2a5746891","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_52d34ecaf34e4db6b879a076a8a0c918","IPY_MODEL_39e24155d4de40cfb9ba3c3d678d9b3b"]}},"73a77396295d481584ba3ff2a5746891":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"52d34ecaf34e4db6b879a076a8a0c918":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9d5d2c73362543ea8f75959a36dbef31","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":481,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":481,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6ed0c9b9a15e4c9196e53deaa6527c26"}},"39e24155d4de40cfb9ba3c3d678d9b3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d530a358eb484cbd90d36842abf80728","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 481/481 [00:00&lt;00:00, 551B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_649ffc91bd8d4c85b3d6eb82f065b094"}},"9d5d2c73362543ea8f75959a36dbef31":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6ed0c9b9a15e4c9196e53deaa6527c26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d530a358eb484cbd90d36842abf80728":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"649ffc91bd8d4c85b3d6eb82f065b094":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef61a20839a84bb29f4877120eda6b95":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1f6af1f0db45462da210f0153d092036","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4c2a3270ee274517b12c173e548dc141","IPY_MODEL_71e93f1ef31344998fd0e3382dd71956"]}},"1f6af1f0db45462da210f0153d092036":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4c2a3270ee274517b12c173e548dc141":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_739d8fb0cc4a4c80bc00dd3402ea2c43","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":657434796,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":657434796,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4ba64be214f04a4cbb9817725389e99d"}},"71e93f1ef31344998fd0e3382dd71956":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_990b1223d2ca4d15b2b528039646a450","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 657M/657M [00:21&lt;00:00, 31.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_154919ace6a24a9c836627d45af4832d"}},"739d8fb0cc4a4c80bc00dd3402ea2c43":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4ba64be214f04a4cbb9817725389e99d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"990b1223d2ca4d15b2b528039646a450":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"154919ace6a24a9c836627d45af4832d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"Zva6MvJyLeWi"},"source":["## Import RoBERTa models from HuggingFace 🤗  into Spark NLP 🚀 \n","\n","Let's keep in mind a few things before we start 😊 \n","\n","- This feature is only in `Spark NLP 3.1.x` and after. So please make sure you have upgraded to the latest Spark NLP release\n","- You can import models for RoBERTa from HuggingFace but they have to be compatible with `TensorFlow` and they have to be in `Fill Mask` category. Meaning, you cannot use RoBERTa models trained/fine-tuned on a specific task such as token/sequence classification."]},{"cell_type":"markdown","metadata":{"id":"MzxB-Nq6cxOA"},"source":["## Export and Save HuggingFace model"]},{"cell_type":"markdown","metadata":{"id":"yNQkhyMHMgkE"},"source":["- Let's install `HuggingFace` and `TensorFlow`. You don't need `TensorFlow` to be installed for Spark NLP, however, we need it to load and save models from HuggingFace.\n","- We lock TensorFlow on `2.4.1` version and Transformers on `4.6.1`. This doesn't mean it won't work with the future releases, but we wanted you to know which versions have been tested successfully."]},{"cell_type":"code","metadata":{"id":"hHXgqiWpMfCY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622476245503,"user_tz":-120,"elapsed":79664,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}},"outputId":"5290a6f5-417a-4a0e-e6d6-2aba664f030c"},"source":["!pip install -q transformers==4.6.1 tensorflow==2.4.1"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 2.3MB 2.9MB/s \n","\u001b[K     |████████████████████████████████| 394.3MB 36kB/s \n","\u001b[K     |████████████████████████████████| 3.3MB 37.0MB/s \n","\u001b[K     |████████████████████████████████| 901kB 40.5MB/s \n","\u001b[K     |████████████████████████████████| 3.8MB 42.7MB/s \n","\u001b[K     |████████████████████████████████| 471kB 41.7MB/s \n","\u001b[K     |████████████████████████████████| 2.9MB 40.1MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Y3AM6bj4P3NS"},"source":["- HuggingFace comes with a native `saved_model` feature inside `save_pretrained` function for TensorFlow based models. We will use that to save it as TF `SavedModel`.\n","- We'll use [roberta-base](https://huggingface.co/roberta-base) model from HuggingFace as an example\n","- In addition to `TFRobertaModel` we also need to save the `RobertaTokenizer`. This is the same for every model, these are assets needed for tokenization inside Spark NLP."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":945,"referenced_widgets":["35e5ee38bc1c437b8df70d2eae183389","788e3ef4ec61409caf40cc45e23f2f1f","a7b6bc5963af4756ad490e86305f5e24","524d70accce44a1296b2bf8cd9044ebf","0ab09f97b5114624b03cda86be5814a8","943998b3cb204d8489ae0c71081e0390","e3866d1d10c74297abd8fe945bfa574e","0e1999f605a44ec089d3d27a5e6d1874","39c01f1f92ce4ecb89e7bafba714ecb3","97e54be966dc4aeebadf2d77161296a8","5bdca68c26394bc8857c14ca792c8e7d","be5a115938c04631a834020b4426fd11","e81d493c5510490da6655865f859d82f","bba854c507044daf8136a9b3368317fa","9240418ef66b42f4b0e4a4b78520bc9f","a646ecf1a46b4d92a03c417fa44bd517","a0b574ea85694a09a617848c2d98ed77","91dc248081da4e12babe1ac606cc80b1","cd4c3c270a0e42b4bae48a161099483d","220c79e165df4ea59ae5c61abab6493b","dd386f5a79b848458aab9b34179e9351","2c57da9a378042ebaa510f6d58eef27c","5ed79516254d41cf99ec61e552d52b36","44387ff2654445c1b304e9ad0ebdda2b","af56cc3ec8044118904cd7e5043e246d","73a77396295d481584ba3ff2a5746891","52d34ecaf34e4db6b879a076a8a0c918","39e24155d4de40cfb9ba3c3d678d9b3b","9d5d2c73362543ea8f75959a36dbef31","6ed0c9b9a15e4c9196e53deaa6527c26","d530a358eb484cbd90d36842abf80728","649ffc91bd8d4c85b3d6eb82f065b094","ef61a20839a84bb29f4877120eda6b95","1f6af1f0db45462da210f0153d092036","4c2a3270ee274517b12c173e548dc141","71e93f1ef31344998fd0e3382dd71956","739d8fb0cc4a4c80bc00dd3402ea2c43","4ba64be214f04a4cbb9817725389e99d","990b1223d2ca4d15b2b528039646a450","154919ace6a24a9c836627d45af4832d"]},"id":"ZaiirlSKNhVD","executionInfo":{"status":"ok","timestamp":1622476348109,"user_tz":-120,"elapsed":102609,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}},"outputId":"6012bcbe-3fc0-415b-f0e8-3ba4f6115ac2"},"source":["from transformers import RobertaTokenizer, TFRobertaModel\n","\n","MODEL_NAME = 'roberta-base'\n","\n","# let's keep the tokenizer variable, we need it later\n","tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n","# let's save the tokenizer\n","tokenizer.save_pretrained('./{}_tokenizer/'.format(MODEL_NAME))\n","\n","model = TFRobertaModel.from_pretrained(MODEL_NAME).save_pretrained(\"./{}\".format(MODEL_NAME), saved_model=True)"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35e5ee38bc1c437b8df70d2eae183389","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39c01f1f92ce4ecb89e7bafba714ecb3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0b574ea85694a09a617848c2d98ed77","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af56cc3ec8044118904cd7e5043e246d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef61a20839a84bb29f4877120eda6b95","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=657434796.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n","- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fdafe58fe50>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fdafe58fe50>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fdb19e3cdd0> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function wrap at 0x7fdb19e3cdd0> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, pooler_layer_call_and_return_conditional_losses, pooler_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, pooler_layer_call_and_return_conditional_losses, pooler_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: ./roberta-base/saved_model/1/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: ./roberta-base/saved_model/1/assets\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"nlgyZuJfS5IB"},"source":["Let's have a look inside these two directories and see what we are dealing with:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p2XCole7TTef","executionInfo":{"status":"ok","timestamp":1622475893386,"user_tz":-120,"elapsed":303,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}},"outputId":"b5eae84c-d956-406c-ac4a-f74c0313820c"},"source":["!ls -l {MODEL_NAME}"],"execution_count":4,"outputs":[{"output_type":"stream","text":["total 487168\n","-rw-r--r-- 1 root root       642 May 31 15:44 config.json\n","drwxr-xr-x 3 root root      4096 May 31 15:44 saved_model\n","-rw-r--r-- 1 root root 498845224 May 31 15:44 tf_model.h5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0DOGz8VUR-r","executionInfo":{"status":"ok","timestamp":1622475893387,"user_tz":-120,"elapsed":9,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}},"outputId":"49e70965-3ee3-4c91-d05c-603e211597d6"},"source":["!ls -l {MODEL_NAME}/saved_model/1"],"execution_count":5,"outputs":[{"output_type":"stream","text":["total 7904\n","drwxr-xr-x 2 root root    4096 May 31 15:44 assets\n","-rw-r--r-- 1 root root 8084231 May 31 15:44 saved_model.pb\n","drwxr-xr-x 2 root root    4096 May 31 15:44 variables\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mcm2UpNxUUQN","executionInfo":{"status":"ok","timestamp":1622475893388,"user_tz":-120,"elapsed":8,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}},"outputId":"b38036da-afd1-46ce-ef43-f1ec428289ee"},"source":["!ls -l {MODEL_NAME}_tokenizer"],"execution_count":6,"outputs":[{"output_type":"stream","text":["total 1336\n","-rw-r--r-- 1 root root 456318 May 31 15:43 merges.txt\n","-rw-r--r-- 1 root root    772 May 31 15:43 special_tokens_map.json\n","-rw-r--r-- 1 root root   1267 May 31 15:43 tokenizer_config.json\n","-rw-r--r-- 1 root root 898822 May 31 15:43 vocab.json\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gZegMvuGTmHt"},"source":["- as you can see, we need the SavedModel from `saved_model/1/` path\n","- we also be needing `vocab.json` and `merges.txt` files from the tokenizer\n","- all we need is to first convert `vocab.json` to `vocab.txt` and copy both `vocab.txt` and `merges.txt` into `saved_model/1/assets` which Spark NLP will look for"]},{"cell_type":"code","metadata":{"id":"ez6MT-RTT7ss","executionInfo":{"status":"ok","timestamp":1622477112526,"user_tz":-120,"elapsed":922,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}}},"source":["# let's save the vocab as txt file\n","with open('{}_tokenizer/vocab.txt'.format(MODEL_NAME), 'w') as f:\n","    for item in tokenizer.get_vocab().keys():\n","        f.write(\"%s\\n\" % item)\n","\n","# let's copy both vocab.txt and merges.txt files to saved_model/1/assets\n","!cp {MODEL_NAME}_tokenizer/vocab.txt {MODEL_NAME}/saved_model/1/assets\n","!cp {MODEL_NAME}_tokenizer/merges.txt {MODEL_NAME}/saved_model/1/assets"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NlJKd2tIU0PD"},"source":["## Import and Save RoBERTa in Spark NLP\n"]},{"cell_type":"markdown","metadata":{"id":"A0FXoxHJc5CU"},"source":["- Let's install and setup Spark NLP in Google Colab\n","- This part is pretty easy via our simple script"]},{"cell_type":"code","metadata":{"id":"8tpW5nkMc53m"},"source":["! wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m_NAgx4hdCGP"},"source":["Let's start Spark with Spark NLP included via our simple `start()` function"]},{"cell_type":"code","metadata":{"id":"xGXPlbLdBvbm"},"source":["import sparknlp\n","# let's start Spark with Spark NLP\n","spark = sparknlp.start()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ABTu9MrdVafM"},"source":["- Let's use `loadSavedModel` functon in `RoBertaEmbeddings` which allows us to load TensorFlow model in SavedModel format\n","- Most params can be set later when you are loading this model in `RoBertaEmbeddings` in runtime, so don't worry what you are setting them now\n","- `loadSavedModel` accepts two params, first is the path to the TF SavedModel. The second is the SparkSession that is `spark` variable we previously started via `sparknlp.start()`\n","- `setStorageRef` is very important. When you are training a task like NER or any Text Classification, we use this reference to bound the trained model to this specific embeddings so you won't load a different embeddings by mistake and see terrible results 😊\n","- It's up to you what you put in `setStorageRef` but it cannot be changed later on. We usually use the name of the model to be clear, but you can get creative if you want! \n","- The `dimension` param is is purely cosmetic and won't change anything. It's mostly for you to know later via `.getDimension` what is the dimension of your model. So set this accordingly.\n"]},{"cell_type":"code","metadata":{"id":"8W_almibVRTj","executionInfo":{"status":"ok","timestamp":1622477246742,"user_tz":-120,"elapsed":10164,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}}},"source":["from sparknlp.annotator import *\n","\n","roberta = RoBertaEmbeddings.loadSavedModel(\n","     '{}/saved_model/1'.format(MODEL_NAME),\n","     spark\n"," )\\\n"," .setInputCols([\"sentence\",'token'])\\\n"," .setOutputCol(\"embeddings\")\\\n"," .setCaseSensitive(True)\\\n"," .setDimension(768)\\\n"," .setStorageRef('roberta_base') "],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PjGiq4KnXWuy"},"source":["- Let's save it on disk so it is easier to be moved around and also be used later via `.load` function"]},{"cell_type":"code","metadata":{"id":"iWu5HfbnXAlM","executionInfo":{"status":"ok","timestamp":1622477590856,"user_tz":-120,"elapsed":344116,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}}},"source":["roberta.write().overwrite().save(\"./{}_spark_nlp\".format(MODEL_NAME))"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4W2m4JuVDM3D"},"source":["Let's clean up stuff we don't need anymore"]},{"cell_type":"code","metadata":{"id":"CnUXH76ADSkL","executionInfo":{"status":"ok","timestamp":1622477590857,"user_tz":-120,"elapsed":15,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}}},"source":["!rm -rf {MODEL_NAME}_tokenizer {MODEL_NAME}"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-TSeTRZpXqWO"},"source":["Awesome 😎  !\n","\n","This is your RoBERTa model from HuggingFace 🤗 loaded and saved by Spark NLP 🚀 "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ogpxSWxOXj3W","executionInfo":{"status":"ok","timestamp":1622477591833,"user_tz":-120,"elapsed":980,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}},"outputId":"8d8fc13b-427e-44f1-bfe4-2705862f8730"},"source":["! ls -l {MODEL_NAME}_spark_nlp"],"execution_count":11,"outputs":[{"output_type":"stream","text":["total 288996\n","drwxr-xr-x 5 root root      4096 May 31 16:07 fields\n","drwxr-xr-x 2 root root      4096 May 31 16:07 metadata\n","-rw-r--r-- 1 root root 295923287 May 31 16:13 roberta_tensorflow\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Fbehje7fYTDj"},"source":["Now let's see how we can use it on other machines, clusters, or any place you wish to use your new and shiny RoBERTa model 😊 "]},{"cell_type":"code","metadata":{"id":"1mm3CvkwYRgs","executionInfo":{"status":"ok","timestamp":1622477610644,"user_tz":-120,"elapsed":16938,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}}},"source":["roberta_loaded = RoBertaEmbeddings.load(\"./{}_spark_nlp\".format(MODEL_NAME))\\\n","  .setInputCols([\"sentence\",'token'])\\\n","  .setOutputCol(\"embeddings\")\\\n","  .setCaseSensitive(True)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"pGRTNISyYlnO","executionInfo":{"status":"ok","timestamp":1622477610651,"user_tz":-120,"elapsed":23,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}},"outputId":"fc4d45f1-d870-408a-e16e-bbf6710bf33d"},"source":["roberta_loaded.getStorageRef()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'roberta_base'"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"_he2LDtBYo1h"},"source":["That's it! You can now go wild and use hundreds of RoBERTa models from HuggingFace 🤗 in Spark NLP 🚀 \n"]},{"cell_type":"code","metadata":{"id":"ywzS9bwfLlI1"},"source":[""],"execution_count":null,"outputs":[]}]}