{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HuggingFace in Spark NLP - BertForSequenceClassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vXYNX2lQROB"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BertForSequenceClassification.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zva6MvJyLeWi"
      },
      "source": [
        "## Import BertForSequenceClassification models from HuggingFace ðŸ¤—  into Spark NLP ðŸš€ \n",
        "\n",
        "Let's keep in mind a few things before we start ðŸ˜Š \n",
        "\n",
        "- This feature is only in `Spark NLP 3.3.2` and after. So please make sure you have upgraded to the latest Spark NLP release\n",
        "- You can import BERT models trained/fine-tuned for token classification via `BertForSequenceClassification` or `TFBertForSequenceClassification`. These models are usually under `Token Classification` category and have `bert` in their labels\n",
        "- Reference: [TFBertForSequenceClassification](https://huggingface.co/transformers/model_doc/bert.html#tfbertforsequenceclassification)\n",
        "- Some [example models](https://huggingface.co/models?filter=bert&pipeline_tag=text-classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzxB-Nq6cxOA"
      },
      "source": [
        "## Export and Save HuggingFace model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNQkhyMHMgkE"
      },
      "source": [
        "- Let's install `HuggingFace` and `TensorFlow`. You don't need `TensorFlow` to be installed for Spark NLP, however, we need it to load and save models from HuggingFace.\n",
        "- We lock TensorFlow on `2.4.1` version and Transformers on `4.8.1`. This doesn't mean it won't work with the future releases, but we wanted you to know which versions have been tested successfully."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHXgqiWpMfCY"
      },
      "source": [
        "!pip install -q transformers==4.8.1 tensorflow==2.4.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3AM6bj4P3NS"
      },
      "source": [
        "- HuggingFace comes with a native `saved_model` feature inside `save_pretrained` function for TensorFlow based models. We will use that to save it as TF `SavedModel`.\n",
        "- We'll use [finiteautomata/beto-sentiment-analysis](https://huggingface.co/finiteautomata/beto-sentiment-analysis) model from HuggingFace as an example\n",
        "- In addition to `TFBertForSequenceClassification` we also need to save the `BertTokenizer`. This is the same for every model, these are assets needed for tokenization inside Spark NLP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaiirlSKNhVD"
      },
      "source": [
        "from transformers import TFBertForSequenceClassification, BertTokenizer \n",
        "\n",
        "MODEL_NAME = 'finiteautomata/beto-sentiment-analysis'\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.save_pretrained('./{}_tokenizer/'.format(MODEL_NAME))\n",
        "\n",
        "try:\n",
        "  model = TFBertForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "except:\n",
        "  model = TFBertForSequenceClassification.from_pretrained(MODEL_NAME, from_pt=True)\n",
        "    \n",
        "model.save_pretrained(\"./{}\".format(MODEL_NAME), saved_model=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlgyZuJfS5IB"
      },
      "source": [
        "Let's have a look inside these two directories and see what we are dealing with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2XCole7TTef"
      },
      "source": [
        "!ls -l {MODEL_NAME}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0DOGz8VUR-r"
      },
      "source": [
        "!ls -l {MODEL_NAME}/saved_model/1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mcm2UpNxUUQN"
      },
      "source": [
        "!ls -l {MODEL_NAME}_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZegMvuGTmHt"
      },
      "source": [
        "- As you can see, we need the SavedModel from `saved_model/1/` path\n",
        "- We also be needing `vocab.txt` from the tokenizer\n",
        "- All we need is to just copy the `vocab.txt` to `saved_model/1/assets` which Spark NLP will look for\n",
        "- In addition to vocabs, we also need `labels` and their `ids` which is saved inside the model's config. We will save this inside `labels.txt`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez6MT-RTT7ss"
      },
      "source": [
        "asset_path = '{}/saved_model/1/assets'.format(MODEL_NAME)\n",
        "\n",
        "!cp {MODEL_NAME}_tokenizer/vocab.txt {asset_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcg_5YP1-vfC"
      },
      "source": [
        "# get label2id dictionary \n",
        "labels = model.config.label2id\n",
        "# sort the dictionary based on the id\n",
        "labels = sorted(labels, key=labels.get)\n",
        "\n",
        "with open(asset_path+'/labels.txt', 'w') as f:\n",
        "    f.write('\\n'.join(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBq7ztzlACYO"
      },
      "source": [
        "Voila! We have our `vocab.txt` and `labels.txt` inside assets directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYnT5U8N9dxT"
      },
      "source": [
        "!ls -l {MODEL_NAME}/saved_model/1/assets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlJKd2tIU0PD"
      },
      "source": [
        "## Import and Save BertForSequenceClassification in Spark NLP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0FXoxHJc5CU"
      },
      "source": [
        "- Let's install and setup Spark NLP in Google Colab\n",
        "- This part is pretty easy via our simple script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tpW5nkMc53m"
      },
      "source": [
        "! wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_NAgx4hdCGP"
      },
      "source": [
        "Let's start Spark with Spark NLP included via our simple `start()` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbNneAVCLU1y"
      },
      "source": [
        "import sparknlp\n",
        "# let's start Spark with Spark NLP\n",
        "spark = sparknlp.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABTu9MrdVafM"
      },
      "source": [
        "- Let's use `loadSavedModel` functon in `BertForSequenceClassification` which allows us to load TensorFlow model in SavedModel format\n",
        "- Most params can be set later when you are loading this model in `BertForSequenceClassification` in runtime like `setMaxSentenceLength`, so don't worry what you are setting them now\n",
        "- `loadSavedModel` accepts two params, first is the path to the TF SavedModel. The second is the SparkSession that is `spark` variable we previously started via `sparknlp.start()`\n",
        "- NOTE: `loadSavedModel` only accepts local paths and not distributed file systems such as `HDFS`, `S3`, `DBFS`, etc. That is why we use `write.save` so we can use `.load()` from any file systems\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W_almibVRTj"
      },
      "source": [
        "from sparknlp.annotator import *\n",
        "\n",
        "sequenceClassifier = BertForSequenceClassification.loadSavedModel(\n",
        "     '{}/saved_model/1'.format(MODEL_NAME),\n",
        "     spark\n",
        " )\\\n",
        "  .setInputCols([\"sentence\",'token'])\\\n",
        "  .setOutputCol(\"class\")\\\n",
        "  .setCaseSensitive(True)\\\n",
        "  .setMaxSentenceLength(128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjGiq4KnXWuy"
      },
      "source": [
        "- Let's save it on disk so it is easier to be moved around and also be used later via `.load` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWu5HfbnXAlM"
      },
      "source": [
        "sequenceClassifier.write().overwrite().save(\"./{}_spark_nlp\".format(MODEL_NAME))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCrjxPhzDplN"
      },
      "source": [
        "Let's clean up stuff we don't need anymore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgkVIJshDtLx"
      },
      "source": [
        "!rm -rf {MODEL_NAME}_tokenizer {MODEL_NAME}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TSeTRZpXqWO"
      },
      "source": [
        "Awesome ðŸ˜Ž  !\n",
        "\n",
        "This is your BertForSequenceClassification model from HuggingFace ðŸ¤—  loaded and saved by Spark NLP ðŸš€ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogpxSWxOXj3W"
      },
      "source": [
        "! ls -l {MODEL_NAME}_spark_nlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbehje7fYTDj"
      },
      "source": [
        "Now let's see how we can use it on other machines, clusters, or any place you wish to use your new and shiny BertForSequenceClassification model ðŸ˜Š "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mm3CvkwYRgs"
      },
      "source": [
        "sequenceClassifier_loaded = BertForSequenceClassification.load(\"./{}_spark_nlp\".format(MODEL_NAME))\\\n",
        "  .setInputCols([\"sentence\",'token'])\\\n",
        "  .setOutputCol(\"class\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGRTNISyYlnO"
      },
      "source": [
        "sequenceClassifier_loaded = BertForSequenceClassification.load(\"./{}_spark_nlp\".format(MODEL_NAME))\\\n",
        ".getCaseSensitive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_he2LDtBYo1h"
      },
      "source": [
        "That's it! You can now go wild and use hundreds of `BertForSequenceClassification` models from HuggingFace ðŸ¤— in Spark NLP ðŸš€ \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGnO67nR5xn_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
